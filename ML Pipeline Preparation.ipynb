{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "\n",
    "### 1. Import libraries and load data from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/iris/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/iris/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/iris/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet','averaged_perceptron_tagger'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "#from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "from sklearn.tree import ExtraTreeClassifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///disaster_clean.db')\n",
    "df = pd.read_sql_table('disaster_clean',con=engine)\n",
    "######REMEMBER TO REMOVE NEXT LINE\n",
    "df = df.sample(frac=0.05).reset_index(drop=True)\n",
    "\n",
    "#  define feature and target variables X and Y\n",
    "\n",
    "X = df['message'].values \n",
    "y = df[df.columns[4:]]\n",
    "category_names = y.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A tokenization function that processes text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(model):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "                     ('features', FeatureUnion([\n",
    "                                                ('text_pipeline', Pipeline([\n",
    "                                                                    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                                                                    ('tfidf', TfidfTransformer())\n",
    "                                                ])),\n",
    "\n",
    "                    ('starting_verb', StartingVerbExtractor())\n",
    "                    ])),\n",
    "    \n",
    "                    ('clf', model)\n",
    "                    ])\n",
    "    return pipeline   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to minize the false negatives as this would mean that the messages are identified as irrelevant in cases they are in reality relevant. Thus we would like to maximize the $recall=\\frac{tp}{tp+fn}$, thus the recall score is more relevant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One category in this project has only one label that 1 , i guess that is child_alone , hence the error.\n",
    "#SVC does not support that.\n",
    "\n",
    "models = [     \n",
    "    #      MultiOutputClassifier(RidgeClassifierCV()), #recall_micro=0.288 f1_micro=0.207 accuracy=0.311\n",
    "   #       MultiOutputClassifier(MLPClassifier()),     #recall_micro=0.280f1_micro=0.391 accuracy=0.257\n",
    "          MultiOutputClassifier(RandomForestClassifier()), # recall_micro=0.143 f1_micro=0.297 accuracy=0.344\n",
    "          MultiOutputClassifier(KNeighborsClassifier()), # recall_micro=0.288 f1_micro=0.407 accuracy=0.268\n",
    "          MultiOutputClassifier(DecisionTreeClassifier())]#, # recall_micro = 0.426 f1_micro=0.447 accuracy=0.154\n",
    "   #       MultiOutputClassifier(ExtraTreeClassifier()), #recall_micro=0.270 f1_micro=0.303, accuracy=0.107\n",
    "   #       MultiOutputClassifier(ExtraTreesClassifier())] #recall_micor=0.207 f1_micro=0.331, \n",
    "      \n",
    "\n",
    "\n",
    "#sklearn.tree.ExtraTreeClassifier\n",
    "#sklearn.ensemble.ExtraTreesClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =7, train_size=0.8)\n",
    "\n",
    "def test_algorithms(pipeline):\n",
    "    kfold = KFold(n_splits=2)\n",
    "    for score in ['accuracy','f1_micro', 'recall_micro']:\n",
    "        print(score)\n",
    "        predicted = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring=score)\n",
    "        print(predicted.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning\n",
    "\n",
    "def grid_search(pipeline):\n",
    "    \n",
    "    parameters = {\n",
    "  #      'features__text_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "  #      'features__text_pipeline__vect__max_df': (0.5, 0.75, 1.0),\n",
    "  #      'features__text_pipeline__vect__max_features': (None, 5000, 10000),\n",
    "  #      'features__text_pipeline__tfidf__use_idf': (True, False),\n",
    "        'features__transformer_weights': (\n",
    "            {'text_pipeline': 1, 'starting_verb': 0.5},\n",
    "            {'text_pipeline': 0.5, 'starting_verb': 1},\n",
    "            {'text_pipeline': 0.8, 'starting_verb': 1},\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # create grid search object\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters, scoring='recall_micro')\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
      "                                                       ccp_alpha=0.0,\n",
      "                                                       class_weight=None,\n",
      "                                                       criterion='gini',\n",
      "                                                       max_depth=None,\n",
      "                                                       max_features='auto',\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       max_samples=None,\n",
      "                                                       min_impurity_decrease=0.0,\n",
      "                                                       min_impurity_split=None,\n",
      "                                                       min_samples_leaf=1,\n",
      "                                                       min_samples_split=2,\n",
      "                                                       min_weight_fraction_leaf=0.0,\n",
      "                                                       n_estimators=100,\n",
      "                                                       n_jobs=None,\n",
      "                                                       oob_score=False,\n",
      "                                                       random_state=None,\n",
      "                                                       verbose=0,\n",
      "                                                       warm_start=False),\n",
      "                      n_jobs=None)\n",
      "accuracy\n",
      "0.3605769230769231\n",
      "f1_micro\n",
      "0.28621997471554994\n",
      "recall_micro\n",
      "0.17878734468720855\n",
      "Training model...\n",
      "Predict on test data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.88      0.28      0.42        50\n",
      "                 offer       0.00      0.00      0.00         4\n",
      "           aid_related       0.78      0.57      0.66       113\n",
      "          medical_help       0.00      0.00      0.00        27\n",
      "      medical_products       0.00      0.00      0.00        15\n",
      "     search_and_rescue       0.00      0.00      0.00         7\n",
      "              security       0.00      0.00      0.00         5\n",
      "              military       0.00      0.00      0.00        11\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       1.00      0.06      0.11        17\n",
      "                  food       0.89      0.30      0.44        27\n",
      "               shelter       1.00      0.03      0.07        29\n",
      "              clothing       0.00      0.00      0.00         5\n",
      "                 money       0.00      0.00      0.00        11\n",
      "        missing_people       0.00      0.00      0.00         3\n",
      "              refugees       0.00      0.00      0.00        10\n",
      "                 death       0.00      0.00      0.00        10\n",
      "             other_aid       0.00      0.00      0.00        36\n",
      "infrastructure_related       0.00      0.00      0.00        12\n",
      "             transport       0.00      0.00      0.00        13\n",
      "             buildings       0.00      0.00      0.00        10\n",
      "           electricity       0.00      0.00      0.00         3\n",
      "                 tools       0.00      0.00      0.00         2\n",
      "             hospitals       0.00      0.00      0.00         1\n",
      "                 shops       0.00      0.00      0.00         2\n",
      "           aid_centers       0.00      0.00      0.00         3\n",
      "  other_infrastructure       0.00      0.00      0.00         9\n",
      "       weather_related       0.84      0.46      0.59        70\n",
      "                floods       0.75      0.12      0.21        25\n",
      "                 storm       0.50      0.10      0.17        20\n",
      "                  fire       0.00      0.00      0.00         1\n",
      "            earthquake       1.00      0.23      0.38        26\n",
      "                  cold       0.00      0.00      0.00         7\n",
      "         other_weather       0.00      0.00      0.00        20\n",
      "         direct_report       0.85      0.40      0.54        43\n",
      "\n",
      "             micro avg       0.82      0.23      0.36       647\n",
      "             macro avg       0.24      0.07      0.10       647\n",
      "          weighted avg       0.54      0.23      0.30       647\n",
      "           samples avg       0.34      0.13      0.18       647\n",
      "\n",
      "MultiOutputClassifier(estimator=KNeighborsClassifier(algorithm='auto',\n",
      "                                                     leaf_size=30,\n",
      "                                                     metric='minkowski',\n",
      "                                                     metric_params=None,\n",
      "                                                     n_jobs=None, n_neighbors=5,\n",
      "                                                     p=2, weights='uniform'),\n",
      "                      n_jobs=None)\n",
      "accuracy\n",
      "0.2096153846153846\n",
      "f1_micro\n",
      "0.37317482990759293\n",
      "recall_micro\n",
      "0.39737006988246837\n",
      "Training model...\n",
      "Predict on test data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.67      0.60      0.63        50\n",
      "                 offer       0.00      0.00      0.00         4\n",
      "           aid_related       0.57      0.81      0.67       113\n",
      "          medical_help       0.20      0.44      0.27        27\n",
      "      medical_products       0.09      0.33      0.15        15\n",
      "     search_and_rescue       0.00      0.00      0.00         7\n",
      "              security       0.00      0.00      0.00         5\n",
      "              military       0.00      0.00      0.00        11\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.17      0.53      0.26        17\n",
      "                  food       0.19      0.56      0.29        27\n",
      "               shelter       0.16      0.45      0.24        29\n",
      "              clothing       0.00      0.00      0.00         5\n",
      "                 money       0.00      0.00      0.00        11\n",
      "        missing_people       0.00      0.00      0.00         3\n",
      "              refugees       0.07      0.40      0.12        10\n",
      "                 death       0.09      0.50      0.16        10\n",
      "             other_aid       0.29      0.11      0.16        36\n",
      "infrastructure_related       0.05      0.25      0.09        12\n",
      "             transport       0.00      0.00      0.00        13\n",
      "             buildings       0.04      0.20      0.07        10\n",
      "           electricity       0.06      0.33      0.10         3\n",
      "                 tools       0.00      0.00      0.00         2\n",
      "             hospitals       0.00      0.00      0.00         1\n",
      "                 shops       0.00      0.00      0.00         2\n",
      "           aid_centers       0.03      0.33      0.05         3\n",
      "  other_infrastructure       0.09      0.22      0.12         9\n",
      "       weather_related       0.43      0.66      0.52        70\n",
      "                floods       0.20      0.56      0.30        25\n",
      "                 storm       0.18      0.55      0.27        20\n",
      "                  fire       1.00      1.00      1.00         1\n",
      "            earthquake       1.00      0.15      0.27        26\n",
      "                  cold       0.00      0.00      0.00         7\n",
      "         other_weather       0.00      0.00      0.00        20\n",
      "         direct_report       0.60      0.58      0.59        43\n",
      "\n",
      "             micro avg       0.26      0.46      0.33       647\n",
      "             macro avg       0.18      0.27      0.18       647\n",
      "          weighted avg       0.34      0.46      0.36       647\n",
      "           samples avg       0.26      0.27      0.22       647\n",
      "\n",
      "MultiOutputClassifier(estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
      "                                                       class_weight=None,\n",
      "                                                       criterion='gini',\n",
      "                                                       max_depth=None,\n",
      "                                                       max_features=None,\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       min_impurity_decrease=0.0,\n",
      "                                                       min_impurity_split=None,\n",
      "                                                       min_samples_leaf=1,\n",
      "                                                       min_samples_split=2,\n",
      "                                                       min_weight_fraction_leaf=0.0,\n",
      "                                                       presort='deprecated',\n",
      "                                                       random_state=None,\n",
      "                                                       splitter='best'),\n",
      "                      n_jobs=None)\n",
      "accuracy\n",
      "0.15576923076923077\n",
      "f1_micro\n",
      "0.439619442143784\n",
      "recall_micro\n",
      "0.43144412717636815\n",
      "Training model...\n",
      "Predict on test data..\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.55      0.54      0.55        50\n",
      "                 offer       0.00      0.00      0.00         4\n",
      "           aid_related       0.57      0.51      0.54       113\n",
      "          medical_help       0.33      0.22      0.27        27\n",
      "      medical_products       0.45      0.60      0.51        15\n",
      "     search_and_rescue       0.00      0.00      0.00         7\n",
      "              security       0.00      0.00      0.00         5\n",
      "              military       0.25      0.09      0.13        11\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.32      0.35      0.33        17\n",
      "                  food       0.67      0.74      0.70        27\n",
      "               shelter       0.58      0.66      0.61        29\n",
      "              clothing       0.75      0.60      0.67         5\n",
      "                 money       0.56      0.45      0.50        11\n",
      "        missing_people       1.00      0.33      0.50         3\n",
      "              refugees       0.25      0.30      0.27        10\n",
      "                 death       0.23      0.30      0.26        10\n",
      "             other_aid       0.27      0.19      0.23        36\n",
      "infrastructure_related       0.05      0.08      0.06        12\n",
      "             transport       0.43      0.23      0.30        13\n",
      "             buildings       0.36      0.50      0.42        10\n",
      "           electricity       0.75      1.00      0.86         3\n",
      "                 tools       0.00      0.00      0.00         2\n",
      "             hospitals       0.00      0.00      0.00         1\n",
      "                 shops       0.00      0.00      0.00         2\n",
      "           aid_centers       0.00      0.00      0.00         3\n",
      "  other_infrastructure       0.05      0.11      0.07         9\n",
      "       weather_related       0.70      0.80      0.75        70\n",
      "                floods       0.58      0.60      0.59        25\n",
      "                 storm       0.50      0.75      0.60        20\n",
      "                  fire       0.33      1.00      0.50         1\n",
      "            earthquake       0.79      0.73      0.76        26\n",
      "                  cold       0.33      0.29      0.31         7\n",
      "         other_weather       0.30      0.15      0.20        20\n",
      "         direct_report       0.38      0.49      0.43        43\n",
      "\n",
      "             micro avg       0.48      0.48      0.48       647\n",
      "             macro avg       0.35      0.36      0.34       647\n",
      "          weighted avg       0.48      0.48      0.47       647\n",
      "           samples avg       0.35      0.28      0.29       647\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/iris/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "    pipeline = make_pipeline(model)\n",
    "    test_algorithms(pipeline)\n",
    "    cv = grid_search(pipeline)\n",
    "    print('Training model...')\n",
    "    cv.fit(X_train, y_train)\n",
    "    print('Predict on test data..')\n",
    "    y_pred = cv.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=category_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
