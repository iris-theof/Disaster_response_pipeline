{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "\n",
    "### 1. Import libraries and load data from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/iris/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/iris/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/iris/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/iris/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet','averaged_perceptron_tagger','stopwords'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    # load data from database\n",
    "    engine = create_engine('sqlite:///disaster_clean.db')\n",
    "    df = pd.read_sql_table('disaster_clean',con=engine)\n",
    "    #  define feature X and target variables y and names of features category_names \n",
    "    #df = df.sample(frac=0.1, random_state=1)\n",
    "    \n",
    "    X = df['message'].values \n",
    "    y = df[df.columns[4:]]\n",
    "    category_names = y.columns.tolist()\n",
    "    \n",
    "    return X, y, category_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A tokenization function that processes text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    #Regex to find urls\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    \n",
    "    # Finds all urls from the provided text\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    \n",
    "    #Replaces all urls found with the \"urlplaceholder\"\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "        \n",
    "    # Normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())    \n",
    "        \n",
    "    # Extracts the word tokens from the provided text    \n",
    "    tokens = word_tokenize(text)\n",
    "      \n",
    "    # Remove stop words\n",
    "    stop = stopwords.words(\"english\")\n",
    "    words = [t for t in tokens if t not in stop]\n",
    "    \n",
    "    #Lemmanitizer to remove inflectional and derivationally related forms of a word\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Makes a list of clean tokens\n",
    "    clean_tokens = []\n",
    "    for tok in words:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(model):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    return pipeline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(y_test, y_pred):\n",
    "    '''\n",
    "    Printing the classification report for each label\n",
    "    Calculating the total accuracy of the model\n",
    "    ''' \n",
    "    \n",
    "    \n",
    "    for i, col in enumerate(y_test):\n",
    "        print('Feature {}: {}'.format(i+1, col))\n",
    "        print(classification_report(y_test[col], y_pred[:, i]))\n",
    "        \n",
    "    accuracy = (y_pred == y_test.values).mean()\n",
    "    print('The model accuracy is {:.3f}'.format(accuracy))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to minize the false negatives as this would mean that the messages are identified as irrelevant in cases they are in reality relevant. Thus we would like to maximize the $recall=\\frac{tp}{tp+fn}$, thus the recall score is more relevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(pipeline, X_train, y_train):\n",
    "    \n",
    "    '''Tuning pipeline parameters'''\n",
    "    \n",
    "    parameters = {'clf__estimator__n_estimators': [120, 140]}\n",
    "\n",
    "    # create grid search object\n",
    "    model = GridSearchCV(pipeline, param_grid=parameters, scoring='recall_micro', cv=4)\n",
    "    print('Training model...')\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.best_params_)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "{'clf__estimator__n_estimators': 140}\n",
      "Predict on test data..\n",
      "Feature 1: request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94      4960\n",
      "           1       0.79      0.51      0.62      1070\n",
      "\n",
      "    accuracy                           0.89      6030\n",
      "   macro avg       0.85      0.74      0.78      6030\n",
      "weighted avg       0.88      0.89      0.88      6030\n",
      "\n",
      "Feature 2: offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5971\n",
      "           1       0.12      0.14      0.13        59\n",
      "\n",
      "    accuracy                           0.98      6030\n",
      "   macro avg       0.56      0.56      0.56      6030\n",
      "weighted avg       0.98      0.98      0.98      6030\n",
      "\n",
      "Feature 3: aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81      3480\n",
      "           1       0.78      0.60      0.68      2550\n",
      "\n",
      "    accuracy                           0.76      6030\n",
      "   macro avg       0.76      0.74      0.74      6030\n",
      "weighted avg       0.76      0.76      0.75      6030\n",
      "\n",
      "Feature 4: medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      5477\n",
      "           1       0.64      0.24      0.35       553\n",
      "\n",
      "    accuracy                           0.92      6030\n",
      "   macro avg       0.78      0.61      0.65      6030\n",
      "weighted avg       0.90      0.92      0.90      6030\n",
      "\n",
      "Feature 5: medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      5687\n",
      "           1       0.62      0.31      0.42       343\n",
      "\n",
      "    accuracy                           0.95      6030\n",
      "   macro avg       0.79      0.65      0.70      6030\n",
      "weighted avg       0.94      0.95      0.94      6030\n",
      "\n",
      "Feature 6: search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5837\n",
      "           1       0.35      0.22      0.27       193\n",
      "\n",
      "    accuracy                           0.96      6030\n",
      "   macro avg       0.66      0.60      0.63      6030\n",
      "weighted avg       0.95      0.96      0.96      6030\n",
      "\n",
      "Feature 7: security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      5889\n",
      "           1       0.12      0.10      0.11       141\n",
      "\n",
      "    accuracy                           0.96      6030\n",
      "   macro avg       0.55      0.54      0.54      6030\n",
      "weighted avg       0.96      0.96      0.96      6030\n",
      "\n",
      "Feature 8: military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5775\n",
      "           1       0.51      0.26      0.34       255\n",
      "\n",
      "    accuracy                           0.96      6030\n",
      "   macro avg       0.74      0.62      0.66      6030\n",
      "weighted avg       0.95      0.96      0.95      6030\n",
      "\n",
      "Feature 9: water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      5591\n",
      "           1       0.70      0.64      0.67       439\n",
      "\n",
      "    accuracy                           0.95      6030\n",
      "   macro avg       0.83      0.81      0.82      6030\n",
      "weighted avg       0.95      0.95      0.95      6030\n",
      "\n",
      "Feature 10: food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      5342\n",
      "           1       0.74      0.73      0.74       688\n",
      "\n",
      "    accuracy                           0.94      6030\n",
      "   macro avg       0.85      0.85      0.85      6030\n",
      "weighted avg       0.94      0.94      0.94      6030\n",
      "\n",
      "Feature 11: shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      5457\n",
      "           1       0.74      0.54      0.63       573\n",
      "\n",
      "    accuracy                           0.94      6030\n",
      "   macro avg       0.85      0.76      0.80      6030\n",
      "weighted avg       0.93      0.94      0.93      6030\n",
      "\n",
      "Feature 12: clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5904\n",
      "           1       0.46      0.33      0.39       126\n",
      "\n",
      "    accuracy                           0.98      6030\n",
      "   macro avg       0.72      0.66      0.69      6030\n",
      "weighted avg       0.97      0.98      0.98      6030\n",
      "\n",
      "Feature 13: money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5840\n",
      "           1       0.43      0.23      0.30       190\n",
      "\n",
      "    accuracy                           0.97      6030\n",
      "   macro avg       0.70      0.61      0.64      6030\n",
      "weighted avg       0.96      0.97      0.96      6030\n",
      "\n",
      "Feature 14: missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5933\n",
      "           1       0.21      0.20      0.20        97\n",
      "\n",
      "    accuracy                           0.98      6030\n",
      "   macro avg       0.60      0.59      0.59      6030\n",
      "weighted avg       0.97      0.98      0.97      6030\n",
      "\n",
      "Feature 15: refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5793\n",
      "           1       0.47      0.28      0.35       237\n",
      "\n",
      "    accuracy                           0.96      6030\n",
      "   macro avg       0.72      0.63      0.67      6030\n",
      "weighted avg       0.95      0.96      0.95      6030\n",
      "\n",
      "Feature 16: death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      5737\n",
      "           1       0.55      0.49      0.52       293\n",
      "\n",
      "    accuracy                           0.96      6030\n",
      "   macro avg       0.76      0.73      0.75      6030\n",
      "weighted avg       0.95      0.96      0.95      6030\n",
      "\n",
      "Feature 17: other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      5205\n",
      "           1       0.59      0.13      0.21       825\n",
      "\n",
      "    accuracy                           0.87      6030\n",
      "   macro avg       0.73      0.56      0.57      6030\n",
      "weighted avg       0.84      0.87      0.83      6030\n",
      "\n",
      "Feature 18: infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      5612\n",
      "           1       0.42      0.06      0.10       418\n",
      "\n",
      "    accuracy                           0.93      6030\n",
      "   macro avg       0.68      0.53      0.53      6030\n",
      "weighted avg       0.90      0.93      0.90      6030\n",
      "\n",
      "Feature 19: transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      5711\n",
      "           1       0.55      0.18      0.27       319\n",
      "\n",
      "    accuracy                           0.95      6030\n",
      "   macro avg       0.75      0.59      0.62      6030\n",
      "weighted avg       0.93      0.95      0.94      6030\n",
      "\n",
      "Feature 20: buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      5662\n",
      "           1       0.58      0.35      0.44       368\n",
      "\n",
      "    accuracy                           0.94      6030\n",
      "   macro avg       0.77      0.67      0.70      6030\n",
      "weighted avg       0.94      0.94      0.94      6030\n",
      "\n",
      "Feature 21: electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5850\n",
      "           1       0.45      0.25      0.32       180\n",
      "\n",
      "    accuracy                           0.97      6030\n",
      "   macro avg       0.71      0.62      0.65      6030\n",
      "weighted avg       0.96      0.97      0.96      6030\n",
      "\n",
      "Feature 22: tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5956\n",
      "           1       0.19      0.12      0.15        74\n",
      "\n",
      "    accuracy                           0.98      6030\n",
      "   macro avg       0.59      0.56      0.57      6030\n",
      "weighted avg       0.98      0.98      0.98      6030\n",
      "\n",
      "Feature 23: hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5939\n",
      "           1       0.20      0.20      0.20        91\n",
      "\n",
      "    accuracy                           0.98      6030\n",
      "   macro avg       0.59      0.59      0.59      6030\n",
      "weighted avg       0.98      0.98      0.98      6030\n",
      "\n",
      "Feature 24: shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5963\n",
      "           1       0.14      0.12      0.13        67\n",
      "\n",
      "    accuracy                           0.98      6030\n",
      "   macro avg       0.56      0.56      0.56      6030\n",
      "weighted avg       0.98      0.98      0.98      6030\n",
      "\n",
      "Feature 25: aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      5907\n",
      "           1       0.23      0.15      0.18       123\n",
      "\n",
      "    accuracy                           0.97      6030\n",
      "   macro avg       0.60      0.57      0.58      6030\n",
      "weighted avg       0.97      0.97      0.97      6030\n",
      "\n",
      "Feature 26: other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5740\n",
      "           1       0.30      0.05      0.09       290\n",
      "\n",
      "    accuracy                           0.95      6030\n",
      "   macro avg       0.63      0.52      0.53      6030\n",
      "weighted avg       0.92      0.95      0.93      6030\n",
      "\n",
      "Feature 27: weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      4314\n",
      "           1       0.85      0.67      0.75      1716\n",
      "\n",
      "    accuracy                           0.87      6030\n",
      "   macro avg       0.86      0.81      0.83      6030\n",
      "weighted avg       0.87      0.87      0.87      6030\n",
      "\n",
      "Feature 28: floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5498\n",
      "           1       0.83      0.51      0.63       532\n",
      "\n",
      "    accuracy                           0.95      6030\n",
      "   macro avg       0.89      0.75      0.80      6030\n",
      "weighted avg       0.94      0.95      0.94      6030\n",
      "\n",
      "Feature 29: storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      5420\n",
      "           1       0.71      0.61      0.66       610\n",
      "\n",
      "    accuracy                           0.94      6030\n",
      "   macro avg       0.84      0.79      0.81      6030\n",
      "weighted avg       0.93      0.94      0.93      6030\n",
      "\n",
      "Feature 30: fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5923\n",
      "           1       0.35      0.32      0.33       107\n",
      "\n",
      "    accuracy                           0.98      6030\n",
      "   macro avg       0.67      0.65      0.66      6030\n",
      "weighted avg       0.98      0.98      0.98      6030\n",
      "\n",
      "Feature 31: earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      5443\n",
      "           1       0.80      0.78      0.79       587\n",
      "\n",
      "    accuracy                           0.96      6030\n",
      "   macro avg       0.89      0.88      0.88      6030\n",
      "weighted avg       0.96      0.96      0.96      6030\n",
      "\n",
      "Feature 32: cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      5866\n",
      "           1       0.48      0.35      0.41       164\n",
      "\n",
      "    accuracy                           0.97      6030\n",
      "   macro avg       0.73      0.67      0.70      6030\n",
      "weighted avg       0.97      0.97      0.97      6030\n",
      "\n",
      "Feature 33: other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5678\n",
      "           1       0.47      0.16      0.24       352\n",
      "\n",
      "    accuracy                           0.94      6030\n",
      "   macro avg       0.71      0.57      0.60      6030\n",
      "weighted avg       0.92      0.94      0.93      6030\n",
      "\n",
      "Feature 34: direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      4805\n",
      "           1       0.73      0.39      0.51      1225\n",
      "\n",
      "    accuracy                           0.85      6030\n",
      "   macro avg       0.80      0.67      0.71      6030\n",
      "weighted avg       0.83      0.85      0.83      6030\n",
      "\n",
      "The model accuracy is 0.942\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X, y, category_names = load_data()\n",
    "# Make Pipeline\n",
    "pipeline = make_pipeline(MultiOutputClassifier(GradientBoostingClassifier(max_depth=6)))   \n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =7, train_size=0.77)\n",
    "# Perform parameter tuning\n",
    "model = grid_search(pipeline, X_train, y_train)\n",
    "print('Predict on test data..')\n",
    "y_pred = model.predict(X_test)\n",
    "scores(y_test, y_pred)\n",
    "\n",
    "#Save model\n",
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
